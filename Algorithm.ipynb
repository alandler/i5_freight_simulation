{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1d6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "# File imports\n",
    "import data\n",
    "from data import select_dataset, get_station_g, ingest_electricity_data, set_random_speed_columns, ingest_pems\n",
    "from replicate_graph import layer_graph\n",
    "from vehicle import Vehicle\n",
    "from simulation import Simulation\n",
    "from visualization import set_draw_attributes\n",
    "from vehicle_list_data import get_utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100ce1c",
   "metadata": {},
   "source": [
    "## Ingest pems for the whole graph (all charging and parking stops)\n",
    "### commented out because it only needs to be done once. Csv already saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318684ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_graph = ingest_pems(\"data/charging_parking_stations_lonlat.csv\", \"data/charging_parking_distances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4c69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save the new csv with all the speeds (from pems ingest above), which will be used for the algorithm\n",
    "# all_graph[1].to_csv(\"data/charging_parking_distances_pemsingested.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1816bfc",
   "metadata": {},
   "source": [
    "## Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c81e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- SCENARIO 0 -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:33<00:00,  7.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : name:  wednesday_debug_2_scenario0_algorithm_0\n",
      "station_utilization_disp_of_avg:   43.90078125\n",
      "station_utilization_avg_of_disp:   44.14869791666667\n",
      "electricity:   0\n",
      "percent_delay:   (1.0, 1.0, 4.529187227438623, 1.2179298304197967, 0.6901577502575181)\n",
      "hours_spent_in_queues:   (0.0, 0.0, 6.2, 0.30405405405405406, 1.0831559480928725)\n",
      "hours_spent_charging:   (0, 0.0, 11, 1.0337837837837838, 2.980602924089082)\n",
      "Highest: 37\n",
      "Lowest: 1\n",
      "________________________________________\n",
      "New Station: 292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alandler/.local/lib/python3.7/site-packages/ipykernel_launcher.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/alandler/.local/lib/python3.7/site-packages/ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "100%|██████████| 12/12 [01:14<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : name:  wednesday_debug_2_scenario0_algorithm_1\n",
      "station_utilization_disp_of_avg:   37.76510416666667\n",
      "station_utilization_avg_of_disp:   37.8390625\n",
      "electricity:   0\n",
      "percent_delay:   (1.0, 1.0, 5.453842132056268, 1.2855760066646609, 0.8155778809344603)\n",
      "hours_spent_in_queues:   (0.0, 0.0, 6.4, 0.31142857142857144, 1.0704528890871856)\n",
      "hours_spent_charging:   (0, 0.0, 11, 1.0357142857142858, 2.9985966105251736)\n",
      "Highest: 16\n",
      "Lowest: 2\n",
      "________________________________________\n",
      "New Station: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:47<00:18,  6.32s/it]"
     ]
    }
   ],
   "source": [
    "number_of_iterations = 3\n",
    "kwh_per_km = 1.9\n",
    "\n",
    "#scenario list: each list inside has three params : charging rate, kwh per km, and battery capacity.\n",
    "# scenario_list = [[45,1.9,215],[90,1.9,215],[45,0.95,215],[45,1.9,430],[90,0.95,430]] \n",
    "# scenario_list = [[90,0.95,430], [45,1.9,430], [45,0.95,215], [90,1.9,215], [45,1.9,215]] \n",
    "scenario_list = [[45,1.9,215]] #single iteration\n",
    "\n",
    "columns = [\"scenario_number\", \"iteration\", \"charging_rate\", \"km_per_kwh\", \"battery_capacity\", \"success\",\n",
    "           \"station_utilization_disp_of_avg\", \"station_utilization_avg_of_disp\", \"electricity\",\n",
    "           \"percent_delay\", \"hours_spent_in_queues\", \"hours_spent_charging\", \n",
    "           \"most_utilized_node\", \"least_utilized_node\",\n",
    "          \"strongly_connected_components\", \"weakly_connected_components\"]\n",
    "results = [columns]\n",
    "\n",
    "basename = \"wednesday_debug_2\"\n",
    "saving_path = \"trials/\"+basename+\"/\"\n",
    "\n",
    "def print_results(sim, scenario, s, n, success=True):\n",
    "    print(success, \": name: \", sim.name)\n",
    "    \n",
    "    if success==True:\n",
    "        print(\"station_utilization_disp_of_avg:  \", sim.metrics['station_utilization_disp_of_avg'])\n",
    "        print(\"station_utilization_avg_of_disp:  \", sim.metrics['station_utilization_avg_of_disp'])\n",
    "        print(\"electricity:  \", sim.metrics['electricity'])\n",
    "        print(\"percent_delay:  \", sim.metrics['percent_delay'])\n",
    "        print(\"hours_spent_in_queues:  \", sim.metrics['hours_spent_in_queues'])\n",
    "        print(\"hours_spent_charging:  \", sim.metrics['hours_spent_charging'])\n",
    "        \n",
    "\n",
    "for scenario, s in zip(scenario_list, range(0,len(scenario_list))):\n",
    "    \n",
    "    print('------- SCENARIO '+str(s)+' -------')\n",
    "    #initialize for wcctici\n",
    "    simulation_length = 12\n",
    "    battery_interval = 20\n",
    "    kwh_per_km = scenario[1]\n",
    "    battery_capacity = scenario[2]\n",
    "    stations_path = \"data/wcctci_stations-updated.csv\"\n",
    "    distances_path = \"data/wcctci_coord_distances.csv\"\n",
    "    \n",
    "    for n in range(0, number_of_iterations):\n",
    "        \n",
    "        #reset the variables for the next iteration\n",
    "        if n==0:\n",
    "            stations_path = \"data/wcctci_stations-updated.csv\"\n",
    "            distances_path = \"data/wcctci_coord_distances.csv\"\n",
    "        else:\n",
    "            stations_path = \"data/algorithm_\"+str(n)+\"_stations.csv\"\n",
    "            distances_path = \"data/algorithm_\"+str(n)+\"_distances.csv\"\n",
    "        name = basename+\"_scenario\"+str(s)+\"_algorithm_\"+str(n)\n",
    "        \n",
    "        ### run and print metrics\n",
    "        sim = Simulation(name, stations_path, distances_path, simulation_length, battery_interval, kwh_per_km, battery_capacity, saving_path)\n",
    "        sim.add_demand_nodes()\n",
    "        success = True\n",
    "        try:\n",
    "            sim.run()\n",
    "            print_results(sim, scenario, s, n, success)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            success = False\n",
    "            print_results(sim, scenario, s, n, success)\n",
    "            continue # don't attempt data analysis on failed iteration, but continue loop\n",
    "\n",
    "        ### get station utilization\n",
    "\n",
    "        #get the station ids in order \n",
    "        current_stations = [int(j) for j in sim.station_g.nodes]\n",
    "\n",
    "#         #get the utilization rate of the stations\n",
    "#         utilization = sim.metrics['station_utilization']\n",
    "        \n",
    "        # Alternative utilization calculation \n",
    "        utilization = get_utilization(sim)\n",
    "        \n",
    "        avg_utilization = {}\n",
    "        for node in current_stations:\n",
    "            avg_utilization[node] = 0\n",
    "            for i in range(len(utilization)):\n",
    "                use_i = utilization[i]\n",
    "                try:\n",
    "                    avg_utilization[node] += use_i[str(node)]\n",
    "                except:\n",
    "                    avg_utilization[node] += 0\n",
    "\n",
    "            avg_utilization[node] = avg_utilization[node]/len(utilization)\n",
    "\n",
    "        utilization = [i for i in avg_utilization.values()]\n",
    "\n",
    "        #get the station that has the highest utilization.\n",
    "        h_st = current_stations[np.argmax(utilization)]\n",
    "\n",
    "        #get the station that has the lowest utilization.\n",
    "        l_st = current_stations[np.argmin(utilization)]\n",
    "\n",
    "        print(\"Highest:\", h_st)\n",
    "        print(\"Lowest:\", l_st)\n",
    "        print(\"________________________________________\")\n",
    "        \n",
    "        # record the results (including highest + lowest utilized nodes)\n",
    "        if success == True:\n",
    "            result = [s, n, scenario[0], scenario[1], scenario[2], True,\n",
    "            sim.metrics['station_utilization_disp_of_avg'], sim.metrics['station_utilization_avg_of_disp'], \n",
    "            sim.metrics['electricity'], sim.metrics['percent_delay'],\n",
    "            sim.metrics['hours_spent_in_queues'], sim.metrics['hours_spent_charging'],\n",
    "            h_st, l_st, \n",
    "           nx.number_strongly_connected_components(sim.battery_g), nx.number_weakly_connected_components(sim.battery_g)]\n",
    "        else:\n",
    "            result = [s, n, scenario[0], scenario[1], scenario[2], False, None, None, None, None, None, None, None, None, None, None]\n",
    "        results.append(result)\n",
    "        \n",
    "        # If that was the last iteration, do not do prep for next iteration\n",
    "        if n==number_of_iterations-1:\n",
    "            break\n",
    "        \n",
    "        ### Find the unused location that is closest to the highly utilized station\n",
    "\n",
    "        #get the map of all parking areas and stations\n",
    "        full_map_dist = pd.read_csv(\"data/charging_parking_distances_pemsingested.csv\")\n",
    "        full_map_loc = pd.read_csv(\"data/charging_parking_stations.csv\")\n",
    "\n",
    "        #keep only the roads that start or end with the high utilization station\n",
    "        h_map = full_map_dist[(full_map_dist.loc[:, 'OriginID'] == h_st) | (full_map_dist.loc[:, 'DestinationID'] == h_st)]\n",
    "\n",
    "        #then we eliminate all of the stations that are already being used.\n",
    "        using_st = current_stations.copy()\n",
    "        using_st.remove(h_st)\n",
    "        h_map = h_map[(~ h_map.loc[:, 'OriginID'].isin(using_st)) & (~ h_map.loc[:, 'DestinationID'].isin(using_st))]\n",
    "\n",
    "        #then we remove the case where we go from h_st to h_st\n",
    "        h_map = h_map[~ ((h_map.loc[:, 'OriginID'] == h_st) & (h_map.loc[:, 'DestinationID'] == h_st))]\n",
    "\n",
    "        #find the shortest edge. If there is more than one, we choose the first one that comes up (hence the 'reset_index' and [0] bellow)\n",
    "\n",
    "        new_origin = h_map[h_map.Total_TravelTime==h_map.Total_TravelTime.min()].reset_index()['OriginID'][0]\n",
    "        new_destination = h_map[h_map.Total_TravelTime==h_map.Total_TravelTime.min()].reset_index()['DestinationID'][0]\n",
    "\n",
    "        #one of the two will be h_st and the other will be the new station location. \n",
    "        if new_origin == h_st:\n",
    "            new_station = new_destination\n",
    "        else:\n",
    "            new_station = new_origin\n",
    "\n",
    "        print(\"New Station:\", new_station)\n",
    "        ### create the new maps with the locations and the distances of the stations that we will be using next\n",
    "\n",
    "        new_stations_list = current_stations + [new_station]\n",
    "        new_stations_list.remove(l_st)\n",
    "\n",
    "        #now we reduce these to the new set of stations. All origins and destinations should be in this list.\n",
    "        new_map_dist = full_map_dist[(full_map_dist.loc[:, 'OriginID'].isin(new_stations_list)) & (full_map_dist.loc[:, 'DestinationID'].isin(new_stations_list))]\n",
    "        new_map_loc = full_map_loc[full_map_loc.loc[:, 'OID_'].isin(new_stations_list)]\n",
    "\n",
    "        #we add the charging rates and capacity- assuming that they are the same as the others (set to 45 and 8)\n",
    "        #TO DO: check this\n",
    "        new_map_loc['charging_rate'] = scenario[0]\n",
    "        new_map_loc['physical_capacity'] = 8\n",
    "\n",
    "        #we change the snapX and snapY columns to lon and lat \n",
    "        new_map_loc = new_map_loc.rename(columns = {'SnapX': 'longitude', 'SnapY': 'latitude'})\n",
    "\n",
    "        #now we save them. \n",
    "        new_map_loc.to_csv(\"data/algorithm_\"+str(n+1)+\"_stations.csv\") \n",
    "        new_map_dist.to_csv(\"data/algorithm_\"+str(n+1)+\"_distances.csv\")\n",
    "        \n",
    "\n",
    "pd.DataFrame(results).to_csv(saving_path+basename+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c605678f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae31df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_utilization = {}\n",
    "# for node in current_stations:\n",
    "#     avg_utilization[node] = 0\n",
    "#     for i in range(len(utilization)):\n",
    "#         use_i = utilization[i]\n",
    "#         try:\n",
    "#             avg_utilization[node] += use_i[str(node)]\n",
    "#         except:\n",
    "#             avg_utilization[node] += 0\n",
    "    \n",
    "#     avg_utilization[node] = avg_utilization[node]/len(utilization)\n",
    "\n",
    "# utilization_list = [i for i in avg_utilization.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e445d9",
   "metadata": {},
   "source": [
    "## Bellow this is  just code I used to think about/ build the algorithm above (Just ignore).\n",
    "### I was thinking about just one iteration, starting from the wcctci pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc00961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the pickle\n",
    "with open('trials/wcctci_04_04_2022_12_15_28.pkl', 'rb') as inp:\n",
    "    res = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91560706",
   "metadata": {},
   "source": [
    "Get the highest and lowest utilized stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2887bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get station utilization\n",
    "\n",
    "#get the station ids in order \n",
    "current_stations = list(res.station_g.nodes)\n",
    "\n",
    "#get the utilization rate of the stations\n",
    "utilization = res.metrics['station_utilization']\n",
    "\n",
    "#get the station that has the highest utilization.\n",
    "h_st = current_stations[np.argmax(utilization)]\n",
    "\n",
    "#get the station that has the lowest utilization.\n",
    "l_st = current_stations[np.argmin(utilization)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b52f0a",
   "metadata": {},
   "source": [
    "Find the unused location that is closest to the highly utilized station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the map of all parking areas and stations\n",
    "full_map_dist = pd.read_csv(\"data/charging_parking_distances.csv\")\n",
    "\n",
    "#keep only the roads that start or end with the high utilization station\n",
    "h_map = full_map_dist[(full_map_dist.loc[:, 'OriginID'] == h_st) | (full_map_dist.loc[:, 'DestinationID'] == h_st)]\n",
    "\n",
    "#then we eliminate all of the stations that are already being used.\n",
    "using_st = current_stations.copy()\n",
    "using_st.remove(h_st)\n",
    "h_map = h_map[(~ h_map.loc[:, 'OriginID'].isin(using_st)) & (~ h_map.loc[:, 'DestinationID'].isin(using_st))]\n",
    "\n",
    "#then we remove the case where we go from h_st to h_st\n",
    "h_map = h_map[~ ((h_map.loc[:, 'OriginID'] == h_st) & (h_map.loc[:, 'DestinationID'] == h_st))]\n",
    "\n",
    "#find the shortest edge. If there is more than one, we choose the first one that comes up (hence the 'reset_index' and [0] bellow)\n",
    "\n",
    "new_origin = h_map[h_map.Total_TravelTime==h_map.Total_TravelTime.min()].reset_index()['OriginID'][0]\n",
    "new_destination = h_map[h_map.Total_TravelTime==h_map.Total_TravelTime.min()].reset_index()['DestinationID'][0]\n",
    "\n",
    "#one of the two will be h_st and the other will be the new station location. \n",
    "if new_origin == h_st:\n",
    "    new_station = new_destination\n",
    "else:\n",
    "    new_station = new_origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135323d6",
   "metadata": {},
   "source": [
    "Now we start to think about re-runing the simulation with this swap (taking out l_st and adding new_station). To do this, we need to create a new map with the locations and the distances of the stations that we will be using next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac180c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stations_list = current_stations + [new_station]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3446cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have \"full_map_dist\" (distances map)\n",
    "#and we need the locations map\n",
    "full_map_loc = pd.read_csv(\"data/charging_parking_stations.csv\")\n",
    "\n",
    "#now we reduce these to the new set of stations. All origins and destinations should be in this list.\n",
    "new_map_dist = full_map_dist[(full_map_dist.loc[:, 'OriginID'].isin(new_stations_list)) & (full_map_dist.loc[:, 'DestinationID'].isin(new_stations_list))]\n",
    "new_map_loc = full_map_loc[(full_map_loc.loc[:, 'OriginID'].isin(new_stations_list)) & (full_map_loc.loc[:, 'DestinationID'].isin(new_stations_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df54e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we save them. \n",
    "new_map_loc.to_csv(\"data/algorithm_\"+str(1)+\"_stations.csv\") ########change the 1\n",
    "new_map_dist.to_csv(\"data/algorithm_\"+str(1)+\"_distances.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aaee2b",
   "metadata": {},
   "source": [
    "Now we can run the next simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c13442",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_length = 12\n",
    "battery_interval = 20\n",
    "km_per_percent = 3.13\n",
    "\n",
    "sim = Simulation(\"data/algorithm_\"+str(1)+\"_stations.csv\", \"data/algorithm_\"+str(1)+\"_distances.csv\", simulation_length, battery_interval, km_per_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db5eeb",
   "metadata": {},
   "source": [
    "# Anna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa713156",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_path = \"data/wcctci_stations-updated.csv\"\n",
    "distances_path = \"data/wcctci_coord_distances.csv\"\n",
    "# stations_df, distances_df = select_dataset(stations_csv_path, distances_csv_path)\n",
    "# station_g = get_station_g(stations_df, distances_df)\n",
    "# battery_g = layer_graph(station_g, 20, km_per_percent= 1.9)\n",
    "simulation_length = 24\n",
    "battery_interval = 20\n",
    "kwh_per_km = 1.9\n",
    "battery_capacity = 215\n",
    "name = 'hi'\n",
    "sim = Simulation(name, stations_path, distances_path, simulation_length, battery_interval, kwh_per_km, battery_capacity)\n",
    "sim.add_demand_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.battery_g.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00638c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.shortest_path(sim.battery_g, \"Long Beach\", \"Reno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10798fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
